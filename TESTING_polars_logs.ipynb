{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import traceback\n",
    "pl.Config(tbl_rows=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE = '/usr/local/var/log/ichrisbirch/ichrisbirch.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file_to_polars_df(filename: str, debug=False, return_errors=False) -> pl.DataFrame:\n",
    "    schema = {\n",
    "        'log_level': pl.Categorical,\n",
    "        'timestamp': pl.Datetime,\n",
    "        'logger_name': pl.String,\n",
    "        'func_name': pl.String,\n",
    "        'lineno': pl.Int16,\n",
    "        'message': pl.String,\n",
    "    }\n",
    "    num_errors = 0\n",
    "    previous_line = ''\n",
    "    next_line = ''\n",
    "    errors = []\n",
    "    was_error = False\n",
    "    last_error = None\n",
    "\n",
    "    def _process_log_line(line: str):\n",
    "        nonlocal num_errors\n",
    "        nonlocal previous_line\n",
    "        nonlocal next_line\n",
    "        nonlocal was_error\n",
    "        nonlocal last_error\n",
    "        try:\n",
    "            part, message = line.strip().split('|')\n",
    "            log_level, timestamp, part = part.strip().rsplit(' ', maxsplit=2)\n",
    "            logger_name, func_name, lineno = part.strip().split(':')\n",
    "            previous_line = line\n",
    "            if was_error:\n",
    "                errors.append(f'NXT LINE: {line.strip()}\\n')\n",
    "            was_error = False\n",
    "            last_error = None\n",
    "        except Exception:\n",
    "            num_errors += 1\n",
    "            errors.append(traceback.format_exc())\n",
    "            errors.append(f'PRE LINE: {previous_line.strip()}')\n",
    "            errors.append(f'ERR LINE: {line.strip()}')\n",
    "            previous_line = line\n",
    "            was_error = True\n",
    "            return None\n",
    "        return {\n",
    "            'log_level': log_level.strip('[] ').strip(),\n",
    "            'timestamp': timestamp.strip(),\n",
    "            'logger_name': logger_name.strip(),\n",
    "            'func_name': func_name.strip(),\n",
    "            'lineno': lineno.strip(),\n",
    "            'message': message.strip(),\n",
    "        }\n",
    "\n",
    "    def _cast_columns(df, schema: dict):\n",
    "        casts = [pl.col(k).cast(v) for k, v in schema.items()]\n",
    "        return df.select(*casts)\n",
    "\n",
    "    def _process_log_file(filename):\n",
    "        with open(filename) as f:\n",
    "            lines = []\n",
    "            for line in f:\n",
    "                if processed := _process_log_line(line):\n",
    "                    lines.append(processed)\n",
    "        return lines\n",
    "\n",
    "    log_lines = _process_log_file(filename)\n",
    "    df = pl.DataFrame(log_lines)\n",
    "    converted = _cast_columns(df, schema)\n",
    "    num_logs = len(log_lines)\n",
    "    print(f'total errors while processing: {num_errors}/{num_logs} - {round(num_errors / num_logs, 4)}%')\n",
    "    if debug:\n",
    "        print()\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "    return converted\n",
    "\n",
    "\n",
    "df = log_file_to_polars_df(LOG_FILE, debug=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by('log_level').len().sort('len', descending=True).plot.bar(x='log_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(['logger_name', 'log_level']).agg(pl.len()).sort(['len'], descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(['func_name']).agg(pl.len()).sort(['len'], descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col('log_level') == 'ERROR').group_by('logger_name').agg(pl.len()).sort(['len'], descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
