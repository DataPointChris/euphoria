{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"iChrisBirch","text":"<p>Docs here</p>"},{"location":"AWS/","title":"AWS","text":""},{"location":"AWS/#iam","title":"IAM","text":""},{"location":"AWS/#groups","title":"Groups","text":"<p><code>admin</code> - Administrator access <code>developer</code> - Access to services</p> <ul> <li>GROUP: <code>admin</code></li> <li>POLICY: <code>AWSAdministratorAccess</code></li> <li>GROUP: <code>developer</code> group has POLICIES</li> <li>POLICY: <code>AllowPassRoleS3DatabaseBackups</code><ul> <li>Allow to assume the <code>S3DatabaseBackups</code> ROLE</li> <li>ROLE: <code>S3DatabaseBackups</code> - S3 Full Access</li> </ul> </li> <li>POLICY: <code>AWSKeyManagementServiceUser</code><ul> <li>Allow to view and use all KMS keys</li> <li>Allow grant to AWSResources (like S3)</li> </ul> </li> <li>POLICY: <code>AmazonRDSFullAccess</code></li> <li>POLICY: <code>AmazonS3FullAccess</code></li> <li>POLICY: <code>AmazonDynamoDBFullAccess</code></li> <li>ROLE: <code>AWSTrustedAdvisorRole</code></li> </ul> <p><code>mermaid graph TB     admin[admin - Administrator access]     developer[developer - Access to services]     AWSAdministratorAccess[AWSAdministratorAccess]     AllowPassRoleS3DatabaseBackups[AllowPassRoleS3DatabaseBackups]     AWSKeyManagementServiceUser[AWSKeyManagementServiceUser]     AmazonRDSFullAccess[AmazonRDSFullAccess]     AmazonS3FullAccess[AmazonS3FullAccess]     AmazonDynamoDBFullAccess[AmazonDynamoDBFullAccess]     AWSTrustedAdvisorRole[AWSTrustedAdvisorRole]     S3DatabaseBackups[S3DatabaseBackups - S3 Full Access]     admin --&gt;|Attached Policy| AWSAdministratorAccess     developer --&gt;|Attached Policy| AllowPassRoleS3DatabaseBackups     developer --&gt;|Attached Policy| AWSKeyManagementServiceUser     developer --&gt;|Attached Policy| AmazonRDSFullAccess     developer --&gt;|Attached Policy| AmazonS3FullAccess     developer --&gt;|Attached Policy| AmazonDynamoDBFullAccess     AllowPassRoleS3DatabaseBackups -.-&gt;|Assume Role| S3DatabaseBackups     style AllowPassRoleS3DatabaseBackups fill:gray,stroke:#333,stroke-width:2px     style S3DatabaseBackups fill:gray,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5</code></p>"},{"location":"AWS/#ec2","title":"EC2","text":""},{"location":"AWS/#ichrisbirch-instances","title":"ichrisbirch instances","text":"<p>US East 1 Security Group: ichrisbirch-sg Key name: ichrisbirch-webserver Ubuntu 22.04</p>"},{"location":"add_new_app/","title":"Adding A New Application","text":"<p>For this document example we will be creating a new app called <code>Items</code></p>  db table <code>items</code>  sqlalchemy model <code>Item</code>  pydantic schema <code>Item</code>  app endpoint <code>/items</code>  api endpoint <code>/items/</code>"},{"location":"add_new_app/#sqlalchemy-model","title":"Sqlalchemy Model","text":"<p> Import new models into <code>ichrisbirch/alembic/env.py</code> </p> <p> Import new models into <code>ichrisbirch/models/__init__.py</code> For easy reference from the module level.</p> <pre><code>from ichrisbirch import models\n\nitem = models.Item(**data)\n</code></pre>"},{"location":"add_new_app/#pydantic-schema","title":"Pydantic Schema","text":"<p> Import new schemas into <code>ichrisbirch/schemas/__init__.py</code> For easy reference from the module level.</p> <pre><code>from ichrisbirch import schemas\n\nitem = schemas.ItemCreate(**data)\n</code></pre>"},{"location":"add_new_app/#application-blueprint","title":"Application Blueprint","text":""},{"location":"add_new_app/#app-routes","title":"App Routes","text":""},{"location":"add_new_app/#application-blueprint-to-app-factory","title":"Application Blueprint to App Factory","text":""},{"location":"add_new_app/#api-router","title":"API Router","text":""},{"location":"add_new_app/#api-endpoints","title":"API Endpoints","text":"<p> Import in <code>ichrisbirch/schemas/__init__.py</code> For easy reference from the module level.</p>"},{"location":"add_new_app/#api-router-to-api-factory","title":"API Router to API Factory","text":""},{"location":"add_new_app/#html-basehtml-and-indexhtml","title":"HTML base.html and index.html","text":""},{"location":"add_new_app/#navigation-link","title":"Navigation Link","text":"<p> Add link to navigation in <code>ichrisbirch/app/templates/base.html</code></p>"},{"location":"add_new_app/#stylesheet","title":"Stylesheet","text":""},{"location":"add_new_app/#tests","title":"Tests","text":""},{"location":"add_new_app/#testing-data","title":"Testing Data","text":"<p>:material-test: Add testing data into <code>tests/testing_data</code>  Import the test data in <code>tests/testing_data/__init__.py</code>  Add testing data to <code>tests/conftest.py/get_test_data()</code></p>"},{"location":"add_new_app/#api-endpoints-tests","title":"API Endpoints Tests","text":""},{"location":"add_new_app/#app-routes-tests","title":"App Routes Tests","text":""},{"location":"add_new_app/#frontend-tests","title":"Frontend Tests","text":""},{"location":"alembic/","title":"Alembic Revision","text":"<p>Run in <code>ichrisbirch/ichrisbirch</code> (where <code>alembic.ini</code> is located)</p>"},{"location":"alembic/#first-run","title":"First Run","text":"<pre><code>export ENVIRONMENT='development' # or 'production'\nalembic revision --autogenerate -m 'Create initial tables'\nalembic upgrade head\n</code></pre>"},{"location":"alembic/#subsequent-runs","title":"Subsequent Runs","text":"<ol> <li> <p>Make the changes to the models and schemas</p> </li> <li> <p>Run a revision to pickup changes in code <code>alembic revision --autogenerate -m 'Add notes field to tasks table'</code></p> <p>Note If this doesn't work perfectly, you must edit the revision file</p> </li> <li> <p>Run the upgrade in the environments</p> </li> </ol> <p>Locally</p> <pre><code>export ENVIRONMENT='development'\nalembic upgrade head\n</code></pre> <p>EC2</p> <pre><code>export ENVIRONMENT='production'\nalembic upgrade head\n</code></pre>"},{"location":"alembic/#troubleshooting","title":"Troubleshooting","text":"<p>Error Alembic is not able to upgrade to the latest because the revisions got out of sync.  </p> <p>Solution Find the last revision that was successfully run (manually by inspecting the database) and then run: <code>alembic stamp &lt;revision&gt;</code> to set the current revision to the last successful one. Then run the upgrade again: <code>alembic upgrade head</code></p>"},{"location":"alembic/#sqlalchemy-create_all-vs-alembic-upgrade","title":"sqlalchemy create_all vs alembic upgrade","text":"<p><code>SQLAlchemy</code> and <code>Alembic</code> are two powerful tools in the Python ecosystem used for database handling and migrations, respectively. They are often used together in projects to manage database schemas and perform database operations. Understanding the difference between <code>SQLAlchemy</code>'s <code>create_all</code> method and <code>Alembic</code>'s <code>upgrade</code> function is crucial for effectively managing database schema changes and migrations.</p>"},{"location":"alembic/#sqlalchemycreate_all","title":"<code>SQLAlchemy.create_all</code>","text":"<p><code>SQLAlchemy</code> is an SQL toolkit and Object-Relational Mapping (ORM) library for Python. It provides a full suite of well known enterprise-level persistence patterns, designed for efficient and high-performing database access.</p> <ul> <li>What it does: The <code>create_all</code> method in <code>SQLAlchemy</code> is used to create all tables that have been defined in your SQLAlchemy models but don't yet exist in the database. It doesn't consider the current state of the database schema. Instead, it blindly attempts to create all the tables (and associated schema elements like indexes) based on the models you've defined. If a table already exists, it simply skips the creation for that table.</li> <li>Usage scenario: <code>create_all</code> is particularly useful in simple projects or during the initial setup of a project's database where you are starting with an empty database and want to construct the schema based on your models' definitions.</li> </ul>"},{"location":"alembic/#alembicupgrade","title":"<code>Alembic.upgrade</code>","text":"<p><code>Alembic</code> is a lightweight database migration tool for usage with <code>SQLAlchemy</code>. It allows you to manage changes to your database schema over time, enabling versioning of your database similarly to how you version your source code.</p> <ul> <li>What it does: The <code>upgrade</code> function in Alembic applies one or more migrations (changes) to the database schema, moving it to a new version. These migrations are written as scripts which define how to apply a change (e.g., add a table, alter a column) and how to revert it. The <code>upgrade</code> command considers the current version of your database and applies all new migrations in sequence up to the latest version or to a specified version.</li> <li>Usage scenario: <code>Alembic.upgrade</code> is used in iterative development and production environments where the state of the database schema evolves over time. It ensures that schema changes are applied in a controlled and versioned manner, allowing for smooth transitions across different versions of your schema as your application grows and changes.</li> </ul>"},{"location":"alembic/#key-differences","title":"Key Differences","text":"<ul> <li>Version control: Alembic allows for version-controlled schema changes, making it possible to migrate your database schema forwards or backwards as needed. <code>SQLAlchemy.create_all</code> does not consider versions of your schema.</li> <li>Sensitivity to existing schema: <code>create_all</code> essentially ignores the current schema state (it won't modify or delete existing tables), while Alembic <code>upgrade</code> scripts can be tailored to alter the current schema precisely and incrementally.</li> <li>Purpose and scope: <code>create_all</code> is a more blunt instrument, best suited for initial schema creation. Alembic, with its <code>upgrade</code> (and corresponding <code>downgrade</code>) commands, supports a more nuanced and controlled approach to database schema evolution.</li> </ul> <p>In summary, while <code>SQLAlchemy.create_all</code> is useful for initial schema creation in simple scenarios, <code>Alembic.upgrade</code> provides a robust framework for managing schema changes over time in a version-controlled, incremental, and reversible manner. For complex projects and in production environments, integrating Alembic for migration management alongside SQLAlchemy for ORM capabilities is considered best practice.</p>"},{"location":"alembic/#how-to-deal-with-database-that-has-got-out-of-sync-with-alembic-revisions-and-alembic-report-target-database-is-not-up-to-date-how-to-find-what-version-of-the-revision-the-database-matches","title":"How to deal with database that has got out of sync with alembic revisions and alembic report Target database is not up to date.  How to find what version of the revision the database matches","text":"<p>When your database schema has gotten out of sync with Alembic revisions, the message \"Target database is not up to date\" typically indicates Alembic detects mismatches between the expected schema version (from your migration scripts) and the current state of your database. Handling this scenario involves a few steps to identify the disparity and resolve it. Here's how you can approach this situation:</p>"},{"location":"alembic/#1-identify-current-database-version","title":"1. Identify Current Database Version","text":"<p>First, check the current schema version of your database. Alembic uses a table (<code>alembic_version</code> by default) to track the current revision of the schema in your database.</p> <p>You can manually check this table:</p> <pre><code>SELECT * FROM alembic_version;\n</code></pre> <p>Or use Alembic's <code>current</code> command:</p> <pre><code>alembic current\n</code></pre> <p>This command displays the current revision that the database is on.</p>"},{"location":"alembic/#2-compare-with-alembic-revision-history","title":"2. Compare with Alembic Revision History","text":"<p>Next, list all the revisions known to Alembic to see where the current database version stands in relation to the migration history.</p> <p>Run the following command to show your migrations history:</p> <pre><code>alembic history\n</code></pre> <p>This command will print a list of revisions. Find where the revision from your database fits within this list. This will inform you whether the database is ahead, behind, or has diverged (if the current revision doesn't exist in your migration chain).</p>"},{"location":"alembic/#3-identify-divergences-or-missing-revisions","title":"3. Identify Divergences or Missing Revisions","text":"<p>If the database's current revision doesn't exist in the migration history from <code>alembic history</code>, it suggests that the database might have applied a revision that has since been deleted or was created from a different branch of your code.</p> <p>In cases where the database is behind, and simply applying newer migrations is required, you can proceed to use <code>alembic upgrade</code> with the target revision you want to apply.</p> <p>However, if the database is ahead or has diverged, you need to assess how to reconcile the differences.</p>"},{"location":"alembic/#4-resolving-divergences","title":"4. Resolving Divergences","text":""},{"location":"alembic/#option-a-manually-adjust-the-databaseschema","title":"Option A: Manually adjust the database/schema","text":"<p>If possible, manually adjust the database schema to match a specific version in your Alembic history, and use <code>alembic stamp</code> to mark it as such, without applying migrations. This can be necessary if the database was manually altered.</p> <pre><code>alembic stamp &lt;revision_id&gt;\n</code></pre>"},{"location":"alembic/#option-b-generate-a-new-migration","title":"Option B: Generate a new migration","text":"<p>You can attempt to autogenerate a new migration that takes into account the current state of the database and the desired state as per your models.</p> <p>Run:</p> <pre><code>alembic revision --autogenerate -m \"Fixing divergence\"\n</code></pre> <p>Review the generated script closely, as it may not be perfect and could require manual adjustments.</p>"},{"location":"alembic/#option-c-revert-to-a-known-good-state","title":"Option C: Revert to a known good state","text":"<p>If all else fails and you have the ability to reset your database to a known good state (usually viable only in development or with available backups), you can revert the database back to a specific revision and reapply migrations from there.</p>"},{"location":"alembic/#5-apply-missing-migrations","title":"5. Apply Missing Migrations","text":"<p>After resolving discrepancies, ensure that your database is at the correct revision and that all necessary migrations are applied.</p> <pre><code>alembic upgrade head\n</code></pre>"},{"location":"alembic/#caution","title":"Caution","text":"<p>Dealing with schema mismatches can lead to data loss or corruption if not handled carefully. Always back up your database before attempting to resolve discrepancies and thoroughly test any changes in a safe environment prior to application in production.</p> <p>Navigating database schema issues can be challenging, but by systematically checking the current state, comparing it with your migration history, and carefully applying corrections, you can resolve discrepancies and get your project back on track.</p>"},{"location":"alembic/#continue","title":"continue","text":""},{"location":"alembic/#6-validate-schema-after-adjustments","title":"6. Validate Schema After Adjustments","text":"<p>After applying the necessary adjustments and migrations, it\u2019s essential to validate that the database schema now matches the expectations of your application and Alembic migrations. Conduct thorough testing to ensure that:</p> <ul> <li>All expected tables, columns, indexes, and other database objects are correctly defined.</li> <li>The application can successfully interact with the database without encountering schema-related errors.</li> <li>Running <code>alembic current</code> reports the correct and expected revision.</li> </ul>"},{"location":"alembic/#7-consider-future-prevention-strategies","title":"7. Consider Future Prevention Strategies","text":"<p>To avoid future discrepancies between your database schema and Alembic revisions, consider implementing strategies that ensure better synchronization and tracking:</p> <ul> <li>Continuous Integration (CI) Checks: Implement CI pipelines that run tests against a database that is always migrated from scratch using current Alembic migrations. This helps catch issues where migrations do not match the application models or are missing.</li> <li>Code Review Processes: Incorporate migration script reviews as part of your development process to catch potential issues early on.</li> <li>Restricted Database Access: Limit who can manually alter the database schema. Ideally, all changes should go through Alembic migrations to ensure that the schema evolution is recorded and versioned.</li> <li>Documenting Manual Changes: In the unavoidable scenario where manual database changes are made, document these changes meticulously. Consider creating corresponding Alembic migrations, even if they are marked as already applied, to ensure the migration history remains an accurate record of the schema's evolution.</li> </ul>"},{"location":"alembic/#8-additional-tools-and-practices","title":"8. Additional Tools and Practices","text":"<ul> <li>Alembic Autogenerate Revisions: While the <code>--autogenerate</code> feature is powerful, it should not be blindly trusted. Always review the generated migration scripts to ensure they accurately represent the desired schema changes and do not inadvertently drop or alter objects.</li> <li>Model Comparison Extensions: For complex projects, consider using or developing tools that help compare the SQLAlchemy models directly against the actual database schema, identifying discrepancies without relying solely on Alembic's version history.</li> <li>Regular Audits: Schedule regular audits of your database schema versus your models and migrations. This proactive approach can help identify issues before they become problematic.</li> <li>Environment Parity: Aim for parity between your development, staging, and production environments in terms of how migrations are applied and managed, reducing the risk of discrepancies arising from differences in how environments are handled.</li> </ul>"},{"location":"alembic/#conclusion","title":"Conclusion","text":"<p>Getting a database schema back in sync with Alembic revisions involves careful diagnosis, proper tool usage, and strategic resolution of discrepancies. It requires a clear understanding of your current schema state, how it deviates from the expected state, and the steps needed to safely reconcile these differences. Implementing preventative strategies and maintaining meticulous records of changes are key to minimizing future synchronization issues, ensuring that your database schema evolution remains manageable, trackable, and aligned with your application's requirements.</p>"},{"location":"alembic/#how-does-alembic-determine-the-order-of-migrations","title":"How Does Alembic Determine the Order of Migrations","text":"<p>Alembic determines the order in which to apply migrations using a couple of key concepts: revision identifiers and down_revision attributes within the migration scripts. These elements create a directed acyclic graph (DAG) of migrations, establishing a clear lineage or path through your migration history. Here's how these components work together to manage migration order:</p>"},{"location":"alembic/#revision-identifiers","title":"Revision Identifiers","text":"<p>Each Alembic migration script is assigned a unique revision identifier (often a hash) when the migration is generated. This identifier uniquely distinguishes each migration in the series of changes made over time.</p>"},{"location":"alembic/#down-revision-attribute","title":"Down Revision Attribute","text":"<p>Within each migration script, there's an attribute named <code>down_revision</code>. This attribute specifies the identifier of the migration that directly precedes the current one in the migration history. The <code>down_revision</code> effectively points back to the migration's parent in the version history tree.</p> <p>For the very first migration in a project, <code>down_revision</code> will be <code>None</code>, indicating that there is no parent migration (i.e., it's the root of the migration tree).</p>"},{"location":"alembic/#upgrade-and-downgrade-sequences","title":"Upgrade and Downgrade Sequences","text":"<p>Given these two components, Alembic constructs a sequence of migrations:</p> <ul> <li> <p>Upgrade: To migrate forward, Alembic starts from the earliest migration whose <code>down_revision</code> is <code>None</code> and follows the chain of <code>revision</code> to <code>down_revision</code> links, applying each migration in turn until it reaches the specified target migration or the latest migration if no target is specified.</p> </li> <li> <p>Downgrade: For migrating backward, Alembic reverses the process, using the current revision as a starting point and following the chain of <code>down_revision</code> values in reverse to apply the <code>downgrade()</code> operations defined in each migration script, until it reaches the specified target revision.</p> </li> </ul>"},{"location":"alembic/#handling-branches","title":"Handling Branches","text":"<p>Alembic also supports branching in migrations. When branches are present, there may be multiple migration scripts with the same <code>down_revision</code>. In this scenario, Alembic uses a \"merge\" migration to bring the divergent branches back into a single linear path. The merge migration specifies multiple <code>down_revision</code> values, identifying each of the branch tips that it reconciles.</p> <p>When applying migrations:</p> <ol> <li> <p>Linear Migrations: In simple, linear migrations, Alembic applies migrations in the straightforward sequence dictated by the single parent-child (<code>down_revision</code> to <code>revision</code>) relationships.</p> </li> <li> <p>Branched Migrations: In branched scenarios, Alembic will apply migrations from each branch as required, until it encounters a merge point. At the merge point, it ensures that all required branches are up to date before applying the merge migration, thus reconciling the branches and continuing forward in a linear fashion from there.</p> </li> </ol>"},{"location":"alembic/#version-table","title":"Version Table","text":"<p>Alembic tracks the current version of the database schema in the <code>alembic_version</code> table, recording which migrations have been applied. This table is crucial for determining the starting point for any migration operation, be it an upgrade or downgrade.</p> <p>In summary, Alembic determines the order of migrations through a combination of unique revision identifiers, parent-child (down_revision) relationships creating a logical sequence, and support for merging branched histories. This structure allows Alembic to manage complex migrations histories with precision and ensure the database schema evolves coherently with the application's requirements.</p>"},{"location":"alembic/#removing-a-revision-that-has-not-been-applied-to-the-database","title":"Removing a Revision That Has Not Been Applied to the Database","text":"<p>If you have an Alembic revision that hasn't been applied to any database yet and you wish to remove it, the process is fairly straightforward since you only need to deal with the revision script(s) in your migrations folder. Here's how you can do it:</p>"},{"location":"alembic/#steps-to-remove-an-unapplied-alembic-revision","title":"Steps to Remove an Unapplied Alembic Revision","text":"<ol> <li> <p>Locate the Revision File: In your project, navigate to the <code>versions</code> directory within your Alembic migrations folder. This folder contains all the revision scripts generated by Alembic.</p> </li> <li> <p>Identify the Revision Script: Each file in the <code>versions</code> directory corresponds to a specific revision. The filename usually starts with the revision ID (a sequence of letters and numbers generated by Alembic) followed by an underscore and a brief description of the migration, e.g., <code>ae1027a6acf_migration_description.py</code>. Identify the script file for the revision you wish to remove. Make sure this is the correct revision by opening the file and verifying its contents, including the revision ID, the <code>down_revision</code>, and the changes it introduces.</p> </li> <li> <p>Delete the Revision File: Simply delete the identified Python script file from the <code>versions</code> directory. This removes the revision from your migrations history, as far as Alembic is concerned.</p> </li> <li> <p>Check if Downstream Revisions Exist: If the revision you're removing has \"child\" revisions (i.e., revisions that list it as their <code>down_revision</code>), you will need to decide how to handle those. You cannot simply delete a revision if later revisions depend on it without risking inconsistencies in your migration path. If such downstream revisions exist, consider the following options:</p> </li> <li>Delete the Downstream Revisions Too: If the downstream revisions also haven't been applied and aren't necessary, you can delete them as well.</li> <li> <p>Rebase the Downstream Revisions: If the downstream revisions need to be kept, you may need to edit their <code>down_revision</code> attributes to reflect the removal of the parent revision. This might involve setting their <code>down_revision</code> to the removed revision's parent or to a new merge revision if the history is more complex.</p> </li> <li> <p>Regenerate Dependency Graph (Optional): If you modified the <code>down_revision</code> of any subsequent migrations, or if you're not sure about the consistency of your migration scripts, you might want to regenerate the Alembic dependency graph. However, this is more about verifying that your revisions are consistent and there are no \u201corphaned\u201d migrations. Alembic doesn't automatically generate a visual graph, but you can check consistency by running <code>alembic history</code> to make sure it outputs a coherent history from your base revision to the head, without any missing links.</p> </li> <li> <p>Update Database Schema Manually if Necessary: If the deleted migration or any of its downstream migrations had been applied to any other environment's database (development, staging, etc.), you'll need to manually adjust those database schemas and possibly the <code>alembic_version</code> table to ensure consistency. This step applies only if the migration was mistakenly said to be unapplied when, in fact, it had been applied somewhere.</p> </li> </ol>"},{"location":"alembic/#delete-caution","title":"Delete Caution","text":"<ul> <li>Be extra careful to ensure that the migration has indeed not been applied to any environment. Removing applied migrations can lead to inconsistencies and errors.</li> <li>Always have a backup of your database and current migration scripts before deleting or modifying them.</li> <li>Remember to communicate with your team about any changes to the migration scripts, especially if other developers might have applied the deleted migration in their local environment.</li> </ul> <p>In summary, removing an unapplied Alembic revision is as simple as deleting its script file from the <code>versions</code> directory, but care should be taken to handle dependency and consistency issues that might arise from doing so.</p>"},{"location":"api/","title":"API","text":""},{"location":"api/#fastapi-crud-endpoints","title":"FastAPI Crud Endpoints","text":"<p>Order matters with endpoints, dynamic routes <code>route/endpoint/{id}</code> are last. They even have to be after other endpoints:</p> <p><code>route/</code> <code>route/endpoint/</code> <code>route/endpoint/extension</code> The two below don't matter the order, only that they are after all of the endpoints that do not take in a path variable. <code>route/{id}</code> <code>route/endpoint/{id}</code> </p>"},{"location":"api/#endpoint-structure","title":"Endpoint Structure","text":""},{"location":"api/#get-vs-post-vs-put-for-updating-resources","title":"GET vs POST vs PUT for Updating Resources","text":"<p>In RESTful API design, it's common to use a POST or PUT request when you want to update a resource.</p> <p>A <code>GET</code> request should be idempotent, meaning that making the same request multiple times should have the same effect as making it once. In your case, marking a task as complete changes the state of the task, so a <code>GET</code> request would not be appropriate.</p> <p>Between <code>POST</code> and <code>PUT</code>, the choice depends on whether you consider marking a task as complete to be a partial update of the task or a creation of a new state for the task.</p> <p>If you consider it to be a partial update, you should use a <code>PUT</code> request. If you consider it to be a creation of a new state, you should use a <code>POST</code> request.</p> <p>In your current implementation, you're using a <code>POST</code> request, which is perfectly fine. If you wanted to use a PUT request, you could change the decorator to <code>@router.put</code> and the route to something like <code>/task/{task_id}/complete/</code>.</p>"},{"location":"api/#endpoint-resource-vs-action-order","title":"Endpoint Resource vs Action Order","text":"<p>The choice between <code>/tasks/{task_id}/complete/</code> and <code>/tasks/complete/{task_id}/</code> is largely a matter of personal preference and the conventions you've established in your project. However, the most common and RESTful way to design the endpoint would be <code>/tasks/{task_id}/complete/</code>.</p> <p>This is because in REST, URLs are used to represent resources, and the components of the URL are used to form a hierarchy of resources. In this case, the task with a specific task_id is the resource, and complete is an action on that resource. So, it makes sense to structure the URL as <code>/tasks/{task_id}/complete/</code>, where complete is a sub-resource of the task.</p> <p>This structure also has the advantage of being consistent with the other endpoints in your code, which use the structure <code>/tasks/{task_id}/</code>.</p>"},{"location":"api/#put-vs-patch","title":"PUT vs PATCH","text":"<p>In RESTful API design, PUT and PATCH are both used to update a resource, but they are used in slightly different ways:</p> <p>PUT is used to update a resource with a complete new version. It's idempotent, meaning that making the same PUT request multiple times will have the same effect as making it once. If you PUT a resource and then PUT it again with the same data, the second request will have no effect.</p> <p>PATCH, on the other hand, is used to update a resource with a partial update. It's not idempotent by nature, meaning that making the same PATCH request multiple times may have different effects. For example, if you PATCH a resource to increment a counter, making the same PATCH request again will increment the counter again.</p> <p>In RESTful API design, a successful <code>PATCH</code> request typically returns a <code>200 OK</code> status code along with the updated resource. This allows the client to see the changes that were made, which might be different from the changes that were requested if some of the changes couldn't be applied.</p> <p>However, if the <code>PATCH</code> request doesn't return the updated resource, it should return a <code>204 No Content</code> status code to indicate that the request was successful but there's no representation to return (i.e., no body).</p>"},{"location":"api/#good-api-design","title":"Good API Design","text":""},{"location":"backups/","title":"Backups","text":"<ol> <li>Install AWS-CLI</li> <li><code>aws configure</code> - Use credentials for running the script</li> </ol> <p>Note</p> <p>There are more thorough instructions in the script: <code>/scripts/postgres-snapshot-to-s3.sh --help</code></p> <p>Postgres Backup: Location: <code>/scripts/postgres-snapshot-to-s3.sh</code></p> <p>MongDB Backup: https://www.cloudsavvyit.com/6059/how-to-set-up-automated-mongodb-backups-to-s3/</p>"},{"location":"cicd/","title":"CICD","text":""},{"location":"cicd/#deploy-docsyml","title":"<code>deploy-docs.yml</code>","text":"<p>Description:</p> <p>Build the docs with mkdocs and run gh-deploy to publish them to github pages with the <code>pages-build-deployment</code> workflow.</p>"},{"location":"cicd/#python-cicdyml","title":"<code>python-cicd.yml</code>","text":"<p>Description:</p>"},{"location":"cicd/#key-for-github-actions-to-access-ec2-instance","title":"Key for Github Actions to Access EC2 Instance","text":"<p><code>ICHRISBIRCH_KEY</code></p> <p>To generate this value locally: <code>cat ichrisbirch-webserver.pem | pbcopy</code> Simply paste into the secret on Github</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#ichrisbirchichrisbirchconfigpy","title":"<code>ichrisbirch/ichrisbirch/config.py</code>","text":"<p>In the Config class, we're setting the env_file based on the ENVIRONMENT variable. If ENVIRONMENT is not recognized, env_file will be None. When env_file is set, pydantic will automatically try to load the variables from the specified file.</p> <p>Also note that since pydantic automatically converts environment variables to their corresponding data types, we don't need to use Optional or Union in our field definitions anymore.</p>"},{"location":"configuration/#flake-8","title":"Flake 8","text":"<p><code>.flake8</code> cannot be loaded from <code>pyproject.toml</code></p>"},{"location":"css/","title":"CSS Notes","text":""},{"location":"css/#flex","title":"Flex","text":"<p>The display: flex and display: inline-flex properties in CSS are used to create a flex container and make its children flex items. The difference between them lies in how the flex container behaves in relation to other elements.</p> <p>display: flex: This makes the container a block-level flex container. A block-level element takes up the full width of its parent element, and it starts and ends with a new line. So, a flex container with display: flex will take up the full width of its parent and will not allow other elements to sit next to it on the same line.</p> <p>display: inline-flex: This makes the container an inline-level flex container. An inline-level element only takes up as much width as it needs, and it does not start or end with a new line. So, a flex container with display: inline-flex will only be as wide as necessary to contain its items, and it will allow other elements to sit next to it on the same line.</p>"},{"location":"css_bem/","title":"CSS BEM","text":"<p>HTML5 semantic elements help structure the content of web pages in a way that is meaningful for both browsers and developers. BEM (Block, Element, Modifier) is a methodology that aims to create reusable components and code sharing in front-end development. It stands for Block, Element, Modifier and provides a way for developers to name their CSS classes in a strict, understandable, and informative way, significantly improving code maintainability and readability.</p> <p>Here\u2019s an example of a medium complexity page using HTML5 semantic tags combined with BEM CSS naming conventions. This example includes a basic layout with a header, navigation, a main content area with an article and sidebar, and a footer.</p>"},{"location":"css_bem/#example-html-structure","title":"Example HTML Structure","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Example Page with HTML5 and BEM&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"style.css\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;header class=\"header\"&gt;\n    &lt;h1 class=\"header__title\"&gt;My Website&lt;/h1&gt;\n    &lt;nav class=\"nav\"&gt;\n        &lt;ul class=\"nav__list\"&gt;\n            &lt;li class=\"nav__item\"&gt;&lt;a class=\"nav__link\" href=\"#home\"&gt;Home&lt;/a&gt;&lt;/li&gt;\n            &lt;li class=\"nav__item\"&gt;&lt;a class=\"nav__link\" href=\"#about\"&gt;About&lt;/a&gt;&lt;/li&gt;\n            &lt;li class=\"nav__item\"&gt;&lt;a class=\"nav__link\" href=\"#contact\"&gt;Contact&lt;/a&gt;&lt;/li&gt;\n        &lt;/ul&gt;\n    &lt;/nav&gt;\n&lt;/header&gt;\n\n&lt;main class=\"main\"&gt;\n    &lt;article class=\"article\"&gt;\n        &lt;h2 class=\"article__title\"&gt;Blog Post Title&lt;/h2&gt;\n        &lt;p class=\"article__meta\"&gt;Posted on &lt;time datetime=\"2023-04-01\"&gt;April 1, 2023&lt;/time&gt;&lt;/p&gt;\n        &lt;div class=\"article__content\"&gt;\n            &lt;p&gt;This is a blog post. It describes something interesting.&lt;/p&gt;\n        &lt;/div&gt;\n    &lt;/article&gt;\n\n    &lt;aside class=\"sidebar\"&gt;\n        &lt;div class=\"sidebar__section\"&gt;\n            &lt;h2 class=\"sidebar__title\"&gt;About Me&lt;/h2&gt;\n            &lt;p&gt;I am a web developer...&lt;/p&gt;\n        &lt;/div&gt;\n        &lt;div class=\"sidebar__section\"&gt;\n            &lt;h2 class=\"sidebar__title\"&gt;Archives&lt;/h2&gt;\n            &lt;ul class=\"sidebar__list\"&gt;\n                &lt;li class=\"sidebar__item\"&gt;March 2023&lt;/li&gt;\n                &lt;li class=\"sidebar__item\"&gt;February 2023&lt;/li&gt;\n                &lt;li class=\"sidebar__item\"&gt;January 2023&lt;/li&gt;\n            &lt;/ul&gt;\n        &lt;/div&gt;\n    &lt;/aside&gt;\n&lt;/main&gt;\n\n&lt;footer class=\"footer\"&gt;\n    &lt;p class=\"footer__text\"&gt;\u00a9 2023 My Website&lt;/p&gt;\n&lt;/footer&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"css_bem/#example-css-using-bem","title":"Example CSS Using BEM","text":"<pre><code>.header {\n    background-color: #f0f0f0;\n    padding: 20px 0;\n}\n\n.header__title {\n    margin: 0;\n    padding: 0 20px;\n}\n\n.nav {\n    background-color: #333;\n}\n\n.nav__list {\n    list-style: none;\n    display: flex;\n    justify-content: center;\n    padding: 0;\n}\n\n.nav__item {\n    margin: 0 10px;\n}\n\n.nav__link {\n    color: white;\n    text-decoration: none;\n}\n\n.main {\n    display: flex;\n    margin: 20px;\n}\n\n.article {\n    flex: 3;\n}\n\n.article__title {\n    color: #333;\n}\n\n.article__meta {\n    font-style: italic;\n}\n\n.sidebar {\n    flex: 1;\n    padding-left: 20px;\n}\n\n.sidebar__title {\n    font-size: 20px;\n}\n\n.footer {\n    background-color: #333;\n    color: white;\n    text-align: center;\n    padding: 10px 0;\n}\n</code></pre>"},{"location":"css_bem/#bem-explanation","title":"BEM Explanation","text":"<ul> <li> <p>Block: Standalone entity that is meaningful on its own (e.g., <code>header</code>, <code>nav</code>, <code>article</code>, <code>sidebar</code>, <code>footer</code>). Blocks can be nested inside each other but should remain independent.</p> </li> <li> <p>Element: A part of a block that has no standalone meaning and is semantically tied to its block (e.g., <code>header__title</code>, <code>nav__link</code>, <code>article__title</code>). Elements are always part of a block, not another element.</p> </li> <li> <p>Modifier: Flags on blocks or elements used to change appearance, behavior, or state (e.g., <code>nav__link--active</code>, although not shown in the example above, would represent an active state of the navigation link).</p> </li> </ul> <p>BEM's naming convention makes the structure of HTML/CSS clear and understandable at a glance, provides a strong contract for developers on a project, and helps avoid CSS naming conflicts by using unique names based on the block-element hierarchy.</p>"},{"location":"developer_setup/","title":"Developer Setup","text":"<ul> <li>1. Programs to install</li> <li>2. Set up git-secret</li> <li>3. Setup the project</li> <li>4. Run the project</li> <li>5. Connecting to the Running Project</li> <li>5.1. App</li> <li>5.2. API</li> <li>6. Links and Notes</li> </ul>"},{"location":"developer_setup/#1-programs-to-install","title":"1. Programs to install","text":"<p>poetry git-secret Docker Desktop</p>"},{"location":"developer_setup/#2-set-up-git-secret","title":"2. Set up git-secret","text":""},{"location":"developer_setup/#3-setup-the-project","title":"3. Setup the project","text":"<pre><code>git clone https://github.com/datapointchris/ichrisbirch.git\n\ncd ichrisbirch/\n\ngit secret reveal\n\npoetry install\n\nsource .venv/bin/activate\n\nexport ENVIRONMENT=development\n\npre-commit install\n\n# Make sure Docker is running\n\npytest\n</code></pre>"},{"location":"developer_setup/#4-run-the-project","title":"4. Run the project","text":"<p>TODO</p> <p>This doesn't work!  I need to figure out another way to run it locally.   Right now it is relying on using local NGINX and Supervisor.</p> <pre><code># App and API are separate applications.\n# App is a flask app that runs the frontend\n# API is FastAPI running the API backend that the frontend connects to\n\n# Run these in separate shells for log separation\n# poetry run python ichrisbirch/runapidev.py\n# poetry run python ichrisbirch/runappdev.py\n</code></pre>"},{"location":"developer_setup/#5-connecting-to-the-running-project","title":"5. Connecting to the Running Project","text":""},{"location":"developer_setup/#51-app","title":"5.1. App","text":"<p>http://127.0.0.1:6000</p>"},{"location":"developer_setup/#52-api","title":"5.2. API","text":"<p>http://127.0.0.1:6200</p>"},{"location":"developer_setup/#6-links-and-notes","title":"6. Links and Notes","text":"<p>GitHub - github/scripts-to-rule-them-all: Set of boilerplate scripts describing the normalized script pattern that GitHub uses in its projects.</p>"},{"location":"documentation/","title":"Documentation","text":"<p>Built with Material for MkDocs</p> <p>Config file: <code>mkdocs.yml</code> Directory: <code>docs/</code> Docs build pipeline: <code>.github/workflows/deploy-docs.yml</code></p> <p>Docs are built using mkdocs automatically on push with the above pipeline, which triggers the <code>pages-build-deployment</code> Github workflow that publishes them to a <code>gh-pages</code> branch and publishes them to <code>datapointchris.github.io/ichrisbirch</code> from that branch.</p> <p>Refer to CICD for a description of the pipeline.</p>"},{"location":"documentation/#github-settings","title":"Github Settings","text":""},{"location":"documentation/#build-and-deployment","title":"Build and deployment","text":"<p>Source: Deploy from a branch</p> <p>Branch: gh-pages / (root)</p> <p>Note</p> <p>Even though this project is using Github Actions to publish the branch, the action is actually using <code>gh-deploy</code> so the source is NOT Github Actions, but rather \"Deploy from a branch\" that <code>gh-deploy</code> sets up.</p> <p>You might have to push the build once the first time to get the <code>gh-pages</code> branch to show up. This is the branch to use, not master, since part of the deploy script used <code>gh-deploy</code> which builds the <code>gh-pages</code> branch.</p> <p>In this branch, the root of the folder is the built docs, NOT /docs, because we are not building from the master branch where the docs live in /docs.</p>"},{"location":"documentation/#custom-domain","title":"Custom Domain","text":"<p>Custom domain: docs.ichrisbirch.com</p> <p>Refer to Domain Names for setting up the subdomain.</p> <p>Note</p> <p>CNAME record needs to be set up before adding the custom domain, or the lookup will fail. CNAME record goes in the <code>/docs</code> folder because that folder is built as the root on the <code>gh-pages</code> branch that is set up with that file when hosting.</p>"},{"location":"documentation/#diagrams","title":"Diagrams","text":"<p>Online FlowChart &amp; Diagrams Editor - Mermaid Live Editor</p> <p>GitHub - mingrammer/diagrams: Diagram as Code for prototyping cloud system architectures</p>"},{"location":"documentation/#todo-read-these-things","title":"TODO: Read these things","text":"<p>Vale.sh - A linter for prose</p> <p>Python's doctest: Document and Test Your Code at Once \u2013 Real Python</p> <p>Awesome documentation example for small project: Documentation \u2014 pypdf 3.5.1 documentation</p> <p>A Guide to Writing Your First Software Documentation \u2014 SitePointSitePoint</p> <p>How to Write Documentation For Your Next Software Development Project</p> <p>Software Documentation Best Practices [With Examples] helpjuice-logo-0307896d1acd18c6a7f52c4256467fb6ca1007315c373af21357496e9ceb49e2</p> <p>Software Documentation Types and Best Practices | by AltexSoft Inc | Prototypr</p> <p>Prepare the documentation for successful software project development</p> <p>How to Write Technical Documentation With Empathy | by Edward Huang | Jan, 2023 | Better Programming</p>"},{"location":"domain_names/","title":"Domain Names","text":"<p>Hosted in <code>AWS Route 53</code> There are 3 hosted zones, one for the top level domain and one for each subdomain.</p>"},{"location":"domain_names/#ichrisbirchcom-hosted-zone","title":"ichrisbirch.com Hosted Zone","text":"<p>This is referred to as the <code>Apex</code> domain, or top level domain.</p> <p>There are 5 records in this hosted zone:</p> Record Name Type Description Value ichrisbirch.com <code>NS</code> Created automatically with the hosted zone AWS Apex Nameservers ichrisbirch.com <code>SOA</code> Created automtaically with the hosted zone AWS DNS api.ichrisbirch.com <code>NS</code> Nameservers from hosted zone <code>NS</code> record AWS API Nameservers docs.ichrisbirch.com <code>CNAME</code> Re-direct from Github Pages to docs subdomain datapointchris.github.io \\www.ichrisbirch.com <code>A</code> Points to the EC2 IP of the webserver EC2 IP (Elastic IP)"},{"location":"domain_names/#apiichrisbirchcom-hosted-zone","title":"api.ichrisbirch.com Hosted Zone","text":"<p>There are 3 records in this hosted zone:</p> Record Name Type Description Value api.ichrisbirch.com <code>A</code> Points to the EC2 IP of the webserver EC2 IP (Elastic IP) api.ichrisbirch.com <code>NS</code> Created automatically with the hosted zone AWS Api Nameservers api.ichrisbirch.com <code>SOA</code> Created automtaically with the hosted zone AWS DNS"},{"location":"domain_names/#docsichrisbirchcom-hosted-zone","title":"docs.ichrisbirch.com Hosted Zone","text":"<p>There are 3 records in this hosted zone:</p> Record Name Type Description Value docs.ichrisbirch.com <code>A</code> Points to the EC2 IP of the webserver Github Servers docs.ichrisbirch.com <code>NS</code> Created automatically with the hosted zone AWS Docs Nameservers docs.ichrisbirch.com <code>SOA</code> Created automtaically with the hosted zone AWS DNS <p>Refer to the Documentation and CICD pages for setting up Github Pages with this subdomain.</p> <p>Use <code>dig {address}</code> to see if the domain looks set up correctly.</p> <p>Danger</p> <p>If the DNS seems to not be updating and the records are not working, be wary of the <code>Browser Cache</code> and history!! <code>Safari</code> kept the old <code>IP</code> in the cache until restart, the only way to see the update was to use a <code>Private Window</code> Check the cache before troubleshooting.</p>"},{"location":"domain_names/#apex-ichrisbirchcom-wwwichrisbirchcom","title":"Apex - <code>ichrisbirch.com ( www.ichrisbirch.com )</code>","text":"<p>There should be a <code>nameserver</code> record created with the <code>hosted zone</code>, and the <code>soa</code> is created automatically. The <code>A</code> record should point to the elastic IP if assigned, or public ip of the instance or load balancer and the name should have subdomain <code>www</code>.  I believe because the domain <code>ichrisbirch.com</code> is the apex, it doesn't need an <code>A</code> record.</p>"},{"location":"domain_names/#apiichrisbirchcom","title":"<code>api.ichrisbirch.com</code>","text":"<p>There should be a <code>nameserver</code> record created with the <code>hosted zone</code> and <code>soa</code>, same as the Apex. The <code>A</code> record should point to the elastic IP.</p> <p>There should be another <code>NS</code> record with the <code>API Nameservers</code> that is attached to the Apex zone. This allows the Apex to know how to discover the subdomain.</p>"},{"location":"domain_names/#docsichrisbirchcom","title":"<code>docs.ichrisbirch.com</code>","text":"<p>The docs are slightly different because they are hosted by <code>github</code>, being served with <code>mkdocs</code>, so they are not sitting on the server like the app (www) and api (api) are. There should be the similar <code>NS</code> and <code>soa</code> records created.  </p> <p>The <code>A</code> record points to the <code>github</code> (I think) hosts where the docs are hosted: <pre><code>\"185.199.108.153\",\n\"185.199.109.153\",\n\"185.199.110.153\",\n\"185.199.111.153\"\n</code></pre> The <code>CNAME</code> record lives at the <code>Apex</code> level, in place of the <code>NS</code> records like the <code>api</code> uses. Since the <code>CNAME</code> is an alias, it is used to alias <code>docs.ichrisbirch.com</code> =&gt; <code>datapointchris.github.io</code></p>"},{"location":"domain_names/#reference","title":"Reference","text":""},{"location":"domain_names/#1-ns-name-server-records","title":"1. NS (Name Server) Records","text":"<p>Purpose: NS records specify the authoritative name servers for a domain. These servers hold the DNS records for the domain. Function: Direct traffic by telling DNS resolvers which nameserver(s) to ask for the specific domain\u2019s information. Usage: Found at the domain's DNS zone and commonly points to multiple nameservers to provide redundancy. Example:</p> <pre><code>example.com. IN NS ns1.example.com.\nexample.com. IN NS ns2.example.com.\n</code></pre>"},{"location":"domain_names/#2-soa-start-of-authority-records","title":"2. SOA (Start of Authority) Records","text":"<p>Purpose: SOA records provide essential information about the DNS zone of a domain, including the primary nameserver, the admin\u2019s contact email, and timing information for zone transfers. Function: Defines the authoritative server and sets the rules for DNS caching, zone transfers, and DNS record updates. Usage: Should be the first record in a DNS zone file, as it contains critical operational data. Example:</p> <pre><code>example.com. IN SOA ns1.example.com. hostmaster.example.com. (\n              2023010101 ; Serial\n              7200       ; Refresh\n              3600       ; Retry\n              1209600    ; Expire\n              3600       ; Minimum TTL\n              )\n</code></pre>"},{"location":"domain_names/#3-a-address-records","title":"3. A (Address) Records","text":"<p>Purpose: A records map a domain or subdomain to an IPv4 address. Function: Translates the human-readable domain names to numerical IP addresses that computers use. Usage: Essential for pointing a domain or subdomain to a web server\u2019s IP address. Example:</p> <p><code>www.example.com. IN A 192.0.2.1</code></p>"},{"location":"domain_names/#4-cname-canonical-name-records","title":"4. CNAME (Canonical Name) Records","text":"<p>Purpose: CNAME records alias one domain name to another. Function: Points one domain/subdomain to another domain/subdomain, allowing management of multiple addresses by changing a single target address. Usage: Useful for pointing multiple subdomains to a single canonical name and to reduce redundancy in DNS management. Example:</p> <p><code>blog.example.com. IN CNAME www.example.com.</code></p>"},{"location":"domain_names/#how-they-relate-to-domains-and-subdomains","title":"How They Relate to Domains and Subdomains","text":"<p>NS Records: Define which servers are authoritative for the domain's DNS records. If you have subdomains, the NS records for the main domain affects them unless specifically overridden.</p> <p>SOA Records: Hold administrative information and control parameters for the DNS zone; they are vital for overall DNS zone health and updates.</p> <p>A Records: Directly tie domain names and subdomains to specific IP addresses. Different subdomains can be mapped to different IPs using A records.</p> <p>CNAME Records: Allow you to point subdomains (or even the root domain if needed) to other domain names, simplifying DNS management. For example, blog.example.com can point to <code>www.example.com</code>, which has an A record, thereby inheriting its IP indirectly.</p> <p>Example Application: For a domain example.com:</p> <ul> <li>NS Records: Point to ns1.example.com and ns2.example.com.</li> <li>SOA Record: Contains administrative details for the DNS zone, like contact info and timing settings.</li> <li>A Record: Points <code>www.example.com</code> to 192.0.2.1.</li> <li>CNAME Record: Points blog.example.com to <code>www.example.com</code>, which has the A record for the actual IP.</li> </ul>"},{"location":"domain_names/#aws-documentation","title":"AWS Documentation","text":"<p>Routing traffic for subdomains - Amazon Route 53Routing traffic for subdomains - Amazon Route 53</p>"},{"location":"git_secret/","title":"git-secret","text":"<p>Danger</p> <p>It seems that if <code>gpg</code> is updated then it causes some or all of the keys to need to be re-imported with <code>git secret</code> Also if there is a mismatch between <code>gpg</code> versions between computers or cicd and macos then it can create an issue. Overall, this is not the best way of handling secrets :sadface:</p>"},{"location":"git_secret/#making-a-secret","title":"Making a Secret","text":"<pre><code># for new repository\ngit secret init\n\n# This user has to have a public GPG key on THIS computer\ngit secret tell ichrisbirch@gmail.com\n\ngit secret add .env\ngit secret hide\n\ngit commit -am 'build: add secret .env file'\n</code></pre>"},{"location":"git_secret/#using-git-secret-with-ec2-instance","title":"Using git-secret with EC2 instance","text":""},{"location":"git_secret/#make-gpg-key-for-ec2-instance-on-local-machine","title":"Make gpg key for EC2 instance on local machine","text":"<pre><code>gpg --gen-key\n# Real name: iChrisBirch EC2\n# Email address: ec2@ichrisbirch.com\n\n# Export and upload keys to EC2 Instance\ngpg --export --armor ec2@ichrisbirch.com &gt; ec2-public.key\ngpg --export-secret-key --armor ec2@ichrisbirch.com &gt; ec2-private.key\nscp -i ~/.ssh/ichrisbirch-webserver.pem ec2-public.key ubuntu@ichrisbirch:~\nscp -i ~/.ssh/ichrisbirch-webserver.pem ec2-private.key ubuntu@ichrisbirch:~\n\n# Project Directory\ngit secret tell ec2@ichrisbirch.com\n# to re-encrypt them with the new authorized user\ngit secret reveal\ngit secret hide\ngit add .\ngit commit -m 'ops: Update secrets with new authorized user'\ngit push\n</code></pre>"},{"location":"git_secret/#import-gpg-key-on-ec2-instance","title":"Import gpg key on EC2 Instance","text":"<pre><code># Import keys\ngpg --import ec2-public.key\ngpg --import ec2-private.key\n\n# Project Directory\ngit pull\ngit secret reveal\n</code></pre>"},{"location":"git_secret/#make-a-gpg-key-for-cicd","title":"Make a gpg key for CICD","text":""},{"location":"git_secret/#make-a-new-key-locally","title":"Make a new key locally","text":"<pre><code># Generate new key, no passphrase\ngpg --gen-key\n# Export the secret key as one line, multiline not allowed\ngpg --armor --export-secret-key datapointchris@github.com | tr '\\n' ',' &gt; cicd-gpg-key.gpg\n# In the repository, make sure to add the new identity to allowed:\ngit secret tell datapointchris@github.com\ngit secret hide\n</code></pre>"},{"location":"git_secret/#add-the-key-to-the-cicd-environment-secrets","title":"Add the key to the CICD environment secrets","text":""},{"location":"git_secret/#add-run-step-to-cicd-workflow","title":"Add Run Step to CICD workflow","text":"<pre><code>- name: \"git-secret Reveal .env files\"\n  run: |\n    # Import private key and avoid the \"Inappropriate ioctl for device\" error\n    echo ${{ secrets.CICD_GPG_KEY }} | tr ',' '\\n' | gpg --batch --yes --pinentry-mode loopback --import\n    git secret reveal\n</code></pre>"},{"location":"git_secret/#expired-gpg-key","title":"Expired GPG key","text":"<p><code>git-secret: warning: at least one key for email(s) is revoked, expired, or otherwise invalid: ichrisbirch@gmail.com</code></p> <p>Expired keys need to have their expiry date extended, which requires the following steps:</p> <pre><code># List keys and subkey(s)\ngpg --list-secret-keys --verbose --with-subkey-fingerprints\n\n&gt;&gt;&gt; sec   ed25519 2022-04-19 [SC] [expired: 2024-04-18]\n&gt;&gt;&gt;       B98C7D8073BB87...\n&gt;&gt;&gt; uid           [ultimate] Chris Birch &lt;ichrisbirch@gmail.com&gt;\n&gt;&gt;&gt; ssb   cv25519 2022-04-19 [E] [expired: 2024-04-18]\n&gt;&gt;&gt;       2E418AB946A0ECA...\n\n# Set new expiry date for key and subkey(s)\ngpg --quick-set-expire B98C7D8073BB87... 1y 2E418AB946A0ECA...\n\n# Check that the keys are no longer expired\ngpg --list-secret-keys --verbose --with-subkey-fingerprints\n\n&gt;&gt;&gt; sec   ed25519 2022-04-19 [SC] [expires: 2025-04-19]\n&gt;&gt;&gt;       B98C7D8073BB87...\n&gt;&gt;&gt; uid           [ultimate] Chris Birch &lt;ichrisbirch@gmail.com&gt;\n&gt;&gt;&gt; ssb   cv25519 2022-04-19 [E] [expires: 2025-04-19]\n&gt;&gt;&gt;       2E418AB946A0ECA...\n\n# Remove the expired email address frogit-secret`\ngit secret removeperson ichrisbirch@gmail.com\n\n&gt;&gt;&gt; git-secret: removed keys.\n&gt;&gt;&gt; git-secret: now [ichrisbirch@gmail.com] do not have an access to the repository.\n&gt;&gt;&gt; git-secret: make sure to hide the existing secrets again.\n\n# Hide the keys without the email (this may not be necessary)\ngit secret hide\n\n&gt;&gt;&gt; git-secret: done. 3 of 3 files are hidden.\n\n# Add the email address as authorized viewer\ngit secret tell ichrisbirch@gmail.com\n\ngit-secret: done. ichrisbirch@gmail.com added as user(s) who know the secret.\n\n# Hide the secrets again\ngit secret hide\n\n&gt;&gt;&gt; git-secret: done. 3 of 3 files are hidden.\n\n# Check status to see that they are hidden\ngit status\n\n&gt;&gt;&gt;        modified:   .dev.env.secret\n&gt;&gt;&gt;        modified:   .gitsecret/keys/pubring.kbx\n&gt;&gt;&gt;        modified:   .gitsecret/keys/pubring.kbx~\n&gt;&gt;&gt;        modified:   .prod.env.secret\n&gt;&gt;&gt;        modified:   .test.env.secret\n</code></pre>"},{"location":"html5_semantic/","title":"Semantic HTML","text":"<p>HTML5 introduced a set of semantic elements that provide meaningful information about the content they wrap, making web pages more readable for both developers and machines (like search engines or screen readers). Below is an example of a basic web page utilizing several common HTML5 semantic tags, along with explanations of when and why each tag is used.</p>"},{"location":"html5_semantic/#example-html5-page-with-semantic-tags","title":"Example HTML5 Page with Semantic Tags","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Example HTML5 Page&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;header&gt;\n    &lt;h1&gt;My Website&lt;/h1&gt;\n    &lt;nav&gt;\n        &lt;ul&gt;\n            &lt;li&gt;&lt;a href=\"#home\"&gt;Home&lt;/a&gt;&lt;/li&gt;\n            &lt;li&gt;&lt;a href=\"#about\"&gt;About&lt;/a&gt;&lt;/li&gt;\n            &lt;li&gt;&lt;a href=\"#contact\"&gt;Contact&lt;/a&gt;&lt;/li&gt;\n        &lt;/ul&gt;\n    &lt;/nav&gt;\n&lt;/header&gt;\n\n&lt;section id=\"home\"&gt;\n    &lt;h2&gt;Welcome to My Website&lt;/h2&gt;\n    &lt;p&gt;This is a paragraph explaining what my website is about.&lt;/p&gt;\n&lt;/section&gt;\n\n&lt;article&gt;\n    &lt;h2&gt;Blog Post Title&lt;/h2&gt;\n    &lt;p&gt;Posted on &lt;time datetime=\"2023-04-01\"&gt;April 1, 2023&lt;/time&gt;&lt;/p&gt;\n    &lt;p&gt;This is a blog post. It contains interesting content about a certain topic.&lt;/p&gt;\n&lt;/article&gt;\n\n&lt;aside&gt;\n    &lt;h2&gt;About Me&lt;/h2&gt;\n    &lt;p&gt;This section provides information about the website owner or related links.&lt;/p&gt;\n&lt;/aside&gt;\n\n&lt;footer&gt;\n    &lt;p&gt;Contact information and copyright notice goes here.&lt;/p&gt;\n&lt;/footer&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"html5_semantic/#explanations-of-semantic-tags","title":"Explanations of Semantic Tags","text":""},{"location":"html5_semantic/#header","title":"<code>&lt;header&gt;</code>","text":"<ul> <li>When to use: For introductory content or navigation links at the top of a section or page.</li> <li>Why: Helps identify the top part of a page or section, often containing the website's logo, navigation links, or titles.</li> </ul>"},{"location":"html5_semantic/#nav","title":"<code>&lt;nav&gt;</code>","text":"<ul> <li>When to use: For navigation links.</li> <li>Why: Indicates a section with navigation links to other pages or parts of the page. Search engines and screen readers can identify the navigation structure of a site more easily.</li> </ul>"},{"location":"html5_semantic/#section","title":"<code>&lt;section&gt;</code>","text":"<ul> <li>When to use: For a thematic grouping of content, typically with a heading.</li> <li>Why: Organizes the page content into thematic groups for easier understanding and navigation. Each <code>&lt;section&gt;</code> should ideally represent a standalone part of the page.</li> </ul>"},{"location":"html5_semantic/#article","title":"<code>&lt;article&gt;</code>","text":"<ul> <li>When to use: For self-contained, independent pieces of content that could be distributed and reused, like blog posts or news articles.</li> <li>Why: Marks content as being a complete, self-contained piece of the page's content. It's important for syndication and when separating document sections that could stand alone or be reused.</li> </ul>"},{"location":"html5_semantic/#aside","title":"<code>&lt;aside&gt;</code>","text":"<ul> <li>When to use: For tangentially related content to the main content, such as sidebars.</li> <li>Why: Differentiates side content from the main content, making it clear that it's supplementary. Good for sidebars, advertising, or content that complements the main content.</li> </ul>"},{"location":"html5_semantic/#footer","title":"<code>&lt;footer&gt;</code>","text":"<ul> <li>When to use: For footer content at the bottom of a section or page.</li> <li>Why: Contains information about the author, copyright notices, contact information, etc. It marks the end of a section or document.</li> </ul>"},{"location":"html5_semantic/#time","title":"<code>&lt;time&gt;</code>","text":"<ul> <li>When to use: To represent a specific period (a date or time).</li> <li>Why: Provides a standard way to encode dates and times in HTML, making it easier for machines to interpret datetime values in a human-readable format.</li> </ul> <p>These semantic elements are crucial for creating a well-structured and accessible webpage, improving both user experience and SEO.</p>"},{"location":"project_layout/","title":"Project Layout","text":""},{"location":"project_layout/#environment-files","title":"Environment Files","text":"<p>Location: <code>/</code> <code>.dev.env</code> <code>.test.env</code> <code>.prod.env</code></p>"},{"location":"project_layout/#project-configuration","title":"Project Configuration","text":"<p>Location: <code>/</code> <code>config.py</code> - Config classes for environments</p>"},{"location":"running_tests/","title":"Running Tests","text":"<p>In order to run pytest, you have to set <code>ENVIRONMENT=development</code> so that the config can pick it up and set the correct variables. Note: Config is not actually setting anything in tests, but the config is called in some of the files that are imported and it will error if not set.</p>"},{"location":"running_tests/#dev-testing-on-mac","title":"Dev Testing on Mac","text":"<ul> <li>Make sure to change <code>/etc/hosts</code> file:   <code>127.0.0.1   localhost</code> --&gt; <code>127.0.0.1 localhost api.localhost books.localhost</code></li> </ul> <p>Docroot is: /usr/local/var/www</p> <p>The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so that nginx can run without sudo.</p> <p>nginx will load all files in /usr/local/etc/nginx/servers/.</p> <p>To restart nginx after an upgrade:   brew services restart nginx Or, if you don't want/need a background service you can just run:   /usr/local/opt/nginx/bin/nginx -g daemon off;</p>"},{"location":"running_tests/#pytest-xdist","title":"<code>pytest-xdist</code>","text":"<p>This plugin does not work with the current configuration (08/28/2024) using a local Docker Postgres and running the app, api, and postgres in a separate thread. <code>pytest-xdist</code> bypasses the start of the docker container and all tests fail.</p>"},{"location":"scheduler/","title":"Scheduler","text":""},{"location":"scheduler/#apscheduler","title":"APScheduler","text":"<p>The scheduler is run in it's own <code>wsgi</code> application managed by <code>supervisor</code>. The scheduler is using the standard blocking scheduler since it is in its own process. Workers need to be set to 1 for <code>gunicorn</code> in order to not start multiple instances of the scheduler. Technically the scheduler could be run as part of the API since the tasks are related to the API, but the API will be changing to async in the future which would require a different scheduler, and the jobs may not always be only related to the API.</p> <p>The jobs are located in the <code>jobs.py</code> file in the <code>/scheduler</code> directory.</p>"},{"location":"scheduler/#current-jobs","title":"Current Jobs","text":"<p><code>decrease_task_priority</code> - Decreases the priority of all tasks by 1 every 24 hours.</p> <p><code>check_and_run_autotasks</code> - Checks if any autotasks need to be run based on their schedule and runs them if so.</p> <p><code>backup_database</code> - Backs up the postgres database to S3 every 3 days.</p>"},{"location":"terraform/","title":"Terraform","text":""},{"location":"terraform/#troubleshooting","title":"Troubleshooting","text":""},{"location":"terraform/#terraform-state-is-locked","title":"Terraform State is Locked","text":"<p>Github Runners sometimes lock the state.</p> <p>Locally: <code>terraform plan</code> -&gt; This will give you an ID of the lock. <code>terraform force-unlock $LOCK_ID</code></p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#flask","title":"Flask","text":"<p>Error</p> <p>Blank pages loading, but no errors.</p> <p>Solution</p> <p>Try a different port Sometimes the port is busy or used, but does not give a 'port in use' error</p>"},{"location":"troubleshooting/#poetry","title":"Poetry","text":"<p>Error</p> <p>ModuleNotFoundError: No module named 'cachecontrol' when running poetry:</p> <p>Solution</p> <p><code>sudo apt install python3-cachecontrol</code></p>"},{"location":"troubleshooting/#supervisor","title":"Supervisor","text":"<p>Error</p> <p>supervisor.sock no such file</p> <p>Solution</p> <p>make sure directories and files for logs are created.</p> <p>Error</p> <p>BACKOFF can't find command... that is pointing to .venv</p> <p>Solution</p> <p>Prod: Check that the project is installed Dev: Check the symlink isn't broken</p> <p>Error</p> <pre><code>error: &lt;class 'FileNotFoundError'&gt;, [Errno 2] No such file or directory: file: /usr/local/Cellar/supervisor/4.2.5/libexec/lib/python3.11/site-packages/supervisor/xmlrpc.py line: 55\n</code></pre> <p>Solution</p> <p>Start and run supervisor with homebrew: <code>brew services start supervisor</code></p> <p>Error</p> <pre><code>FileNotFoundError: [Errno 2] No such file or directory: '/var/www/ichrisbirch/ichrisbirch/NoneNone/pylogger.log'\n</code></pre> <p>Solution</p> <p>The environment file has not been loaded. Most likely you need to run <code>git secret reveal</code> This happens when the project has been cloned for the first time or directory has been deleted or the env files might have changed.</p>"},{"location":"troubleshooting/#nginx","title":"NGINX","text":"<p>Error</p> <p>bind() to 0.0.0.0:80 failed (98: Address already in use)</p> <p>Solution</p> <p><code>sudo pkill -f nginx &amp; wait $!</code> <code>sudo systemctl start nginx</code></p> <p>Error</p> <p>DEV bind() to 127.0.0.1:80 failed (13: Permission denied)</p> <p>Solution</p> <p>NGINX is not running as root.  It does not run reliably with homebrew. Use <code>sudo nginx -s reload</code> instead of homebrew.</p>"},{"location":"troubleshooting/#api-postgres","title":"API Postgres","text":"<p>Error</p> <p>[error] 94580#0: *18 kevent() reported that connect() failed (61: Connection refused) while connecting to upstream, client: 127.0.0.1, server: api.localhost, request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:4200/\", host: \"api.macmini.local</p> <p>Solution</p> <p>DB cannot connect.  Postgres string was built wrong, corrected by adding a test to check config is loaded properly.</p> <p>Error</p> <p>Local changes were working but nothing that connected to prod postgres.</p> <p><code>api.ichrisbirch.com/tasks/</code> - 502 Bad Gateway <code>api.ichrisbirch.com</code> Success redirect to <code>/docs</code> <code>ichrisbirch.com</code> redirects to www in browser but error with requests <code>www.ichrisbirch.com/tasks/</code> - Internal Server Error Can connect to prod server with DBeaver Verified that the connection info is the same. Seems that the API is not connecting to postgres instance</p> <p>api.macmini.local WORKING api.macmini.local/ WORKING api.macmini.local/docs WORKING api.macmini.local/tasks WORKING api.macmini.local/tasks/1 WORKING api.macmini.local/tasks/completed</p> <p>ichrisbirch.com WORKING api.ichrisbirch.com/ WORKING api.ichrisbirch.com/docs ERROR api.ichrisbirch.com/tasks ERROR api.ichrisbirch.com/tasks/1 ERROR api.ichrisbirch.com/tasks/completed</p> <p>Solution</p> <p>The issue was resolved by modifying the security group of the postgres instance to allow the ec2 instance to connect by allowing it's security group.</p>"},{"location":"troubleshooting/#pytest","title":"Pytest","text":"<p>Error</p> <p>E       assert 307 == 200 E        +  where 307 = &lt;Response [307]&gt;.status_code</p> <p>Solution</p> <p>The trailing <code>/</code> is missing from the endpoint being called in the test, resulting in a 307 Temporary Redirect To fix: <code>/endpoint</code> --&gt; <code>/endpoint/</code></p>"},{"location":"troubleshooting/#alembic","title":"Alembic","text":"<p>Error</p> <p>Alembic is not able to upgrade to the latest because the revisions got out of sync.</p> <p>Solution</p> <p>Find the last revision that was successfully run (manually by inspecting the database) and then run: <code>alembic stamp &lt;revision&gt;</code> to set the current revision to the last successful one. Then run the upgrade again: <code>alembic upgrade head</code></p>"},{"location":"troubleshooting/#fastapi","title":"FastAPI","text":"<p>Error</p> <p>Request Error: Client error '405 Method Not Allowed' for url xxx</p> <p>Solution</p> <p>Make sure that the <code>id</code> is being passed correctly for routes like <code>/endpoint/{id}/</code> The error will not say <code>id</code> is not found, it will give a 405 error because the url is not correct</p> <p>Error</p> <p><code>PATCH</code> endpoint giving: 422 Unprocessable Entity: {\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"id\"],\"msg\":\"Field required\"</p> <p>Solution</p> <p><code>PATCH</code> endpoints require the ID in the endpoint, but also the ID must be passed in the payload for the model so it can update the record in the DB by ID.</p>"},{"location":"devops/","title":"DevOps","text":""},{"location":"devops/#scripts-that-run-periodically","title":"Scripts that Run periodically","text":"<p><code>scripts/postgres-snapshot-to-s3.sh</code> <code>scripts/create-project-stats.sh</code></p>"},{"location":"devops/#supervisor","title":"Supervisor","text":""},{"location":"devops/#nginx","title":"NGINX","text":""},{"location":"devops/#new-server-setup","title":"New Server Setup","text":""},{"location":"devops/new_database/","title":"Setup a New Postgres Database","text":""},{"location":"devops/new_database/#schemas","title":"Schemas","text":"<p>SQLAlchemy cannot create the schemas, neither can alembic, have to create them manually first time <code>create-schemas.py</code> to add the schemas</p>"},{"location":"devops/new_database/#alembic","title":"Alembic","text":"<p>Run in <code>ichrisbirch</code></p> <p>Create the initial tables from the SQLAlchemy models (purpose of --autogenerate) <code>alembic revision --autogenerate -m 'init_tables'</code></p> <p>Run the upgrade to actually create the tables <code>alembic upgrade head</code></p>"},{"location":"devops/new_server/","title":"Setup a New Server","text":""},{"location":"devops/new_server/#installs","title":"Installs","text":"<pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n\n# base installs\nsudo apt install curl git git-secret -y\n\n# NOTE: Install the postgresql-client version that matches the database, this is for pg_dump backups with the scheduler.\nsudo apt install postgresql-client-16 tmux tldr supervisor nginx neovim pipx -y\n\n# for pyenv\nsudo apt install build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev -y\n\n# for building psycopg from source\nsudo apt install python3-dev libpq-dev -y\n\n# make sure\npipx ensurepath\n\n# Install pyenv\ncurl https://pyenv.run | bash\n\necho 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.bashrc\necho 'command -v pyenv &gt;/dev/null || export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.bashrc\necho 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.bashrc\n\nexec $SHELL\n\n# Install python\npyenv install 3.12\npyenv global 3.12\n\n# Install poetry making sure to use pyenv python\npipx install --python $(/home/ubuntu/.pyenv/bin/pyenv which python) poetry\n\nsudo chown ubuntu /var/www\n\n##### AT THIS POINT THE AMI SHOULD BE MADE #####\n\n# Clone project\ngit clone https://github.com/datapointchris/ichrisbirch /var/www/ichrisbirch\ncd /var/www/ichrisbirch\n\n# REFER to https://docs.ichrisbirch.com/git_secret/ to get gpg key for git-secret\n\n# Install project\npoetry config virtualenvs.in-project true\n\n# Make log files for project\n./scripts/make_log_files.sh\n\n# Set up nginx and supervisor\nsudo rm /etc/nginx/sites-enabled/default\n\ncd deploy\n./deploy-nginx.sh\n\n./deploy-supervisor.sh\n</code></pre> <p>Change the elastic IP to point to the new server (if only using one server and not load balancer).</p>"},{"location":"devops/nginx/","title":"NGINX","text":""},{"location":"devops/nginx/#how-to-deploy","title":"How to Deploy","text":""},{"location":"devops/pg_cron/","title":"pg_cron","text":"<p>Location: <code>/scripts/sql/pg_cron_setup.sql</code></p> <ol> <li>pg_cron must be added to 'shared_preload_libraries'</li> <li>Reboot required</li> <li>pg_cron runs in the default postgres database, then jobs can be moved to specific databases</li> <li>For AWS RDS: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/PostgreSQL_pg_cron.html</li> </ol>"},{"location":"devops/pg_cron/#basic-instructions","title":"Basic Instructions","text":"<ol> <li>Create a function / procedure to run</li> <li>Schedule it with a name</li> <li>Set the database name for the job to the correct db</li> <li>Check that the job details show it has run successfully</li> </ol> <p>Note</p> <p><code>pg_cron</code> is not being used anymore, in favor of <code>APScheduler</code> in the <code>ichrisbirch/scheduler</code> directory.</p>"},{"location":"devops/supervisor/","title":"Supervisor","text":""},{"location":"devops/supervisor/#how-to-deploy","title":"How to Deploy","text":""}]}